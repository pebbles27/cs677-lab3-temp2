# 677 Lab 3 - Asterix and Multi-Trader Trouble

## Replication, Fault Tolerance and Cache Consistency

## Overview

This project simulates a distributed trading system with 6-8 peers (buyers, sellers, and 2 traders) communicating via Python's multiprocessing module. Configure peer settings and network topology in `config_ts.json`.

## Core Features

1. **Isolated Peer Communication**: Peers run in isolated processes using Python's Multiprocessing module for robust and independent communication.
2. **Cache-Based Approach**: Traders handle buy and sell requests locally using cached inventory, synchronized periodically with the warehouse.
3. **Lamport Clocks for Ordering**: Ensures global consistency and proper sequencing of buy and sell requests across the system.
4. **Heartbeat Protocol**: Detects trader failures within a 3-second timeout, enabling quick failover and maintaining system reliability.
5. **Priority Queues for Products**: Handles product-specific requests efficiently with logical ordering for fairness and consistency.

## Features

- Robust peer-to-peer communication using isolated processes with Python's Multiprocessing module.
- Efficient cache-based inventory management with periodic synchronization and overselling/underselling tracking.
- Global consistency ensured with Lamport clocks for buy and sell request ordering across distributed traders.
- Advanced fault tolerance using heartbeat protocols with seamless failover and request reprocessing.
- Product-specific priority queues with logical time ordering for fair and accurate request handling.
- Comprehensive handling of overselling and underselling scenarios, with detailed logging and CSV-based evaluation.

## Execution Instructions

1. **Setup**:

   - Download and extract the provided ZIP file.
   - Navigate to the project directory.
   - Verify Python version `>=3.5` is installed by running:
     ```bash
     python --version
     ```
   - Install the required dependencies:
     ```bash
     pip install -r requirements.txt
     ```

2. **Execution**:

   - **Windows**:
     ```bash
     python windows_run.py
     ```
   - **Mac/Linux**:
     ```bash
     python run_nodes.py
     ```
3. **To simulate a failure**
    ```bash
     Close the terminal of the trader to quit the process
     ```

   

## File Descriptions

- **`peer.py`**: Defines peer behavior, including buyer, seller, and trader roles, and handles distributed processes like elections and requests.
- **`peer_cache.py`**: Implements peer logic with caching for inventory data and fault handling in distributed trading operations.
- **`warehouse.py`**: Manages inventory updates and processes buyer/seller requests in the distributed system.
- **`config_ts.json`**: Contains peer configurations and network topology for different scenarios (6, 7, or 8 peers).
- **`topology{x}.json`**: Defines network connectivity between peers for various configurations (e.g., 6, 7, or 8 nodes).
- **`stock.json`**: Stores the initial stock levels and prices for products in the warehouse.
- **`run_nodes.py`** and **`windows_run.py`**: Platform-specific scripts to launch peers as sellers/buyers/traders and warehouse.
- **`requirements.txt`**: Dependency file for installing necessary Python packages.
- **`bully.proto`**: Protocol buffer definition for gRPC communication.
- `bully_pb2.py` and `bully_pb2_grpc.py`: the files are auto-generated by the `protoc` compiler to define the protocol buffer message classes and gRPC service stubs for server and client communication.

## Key Components

- **Peer Structure and Communication**: Peers run as isolated processes using Python's Multiprocessing module with interprocess messaging to simulate a distributed environment.
- **Database Server Process**: The warehouse is implemented as a separate database server with a `.csv` file for inventory, using priority queues to handle concurrent buy and sell requests.
- **Traders Electing Procedure**: Two traders are elected using the Bully algorithm; the primary trader is elected first, followed by the secondary trader, excluding the primary trader from the second election.
- **Trading Process**: Traders handle buy and sell requests using local caches, logging transactions in `.txt` files and periodically syncing with the warehouse for consistency.
- **Cache Consistency Model**: A push and stateless model ensures cache consistency, with Lamport clocks maintaining global order and priority queues for sequential request processing.
- **Heartbeat Protocol**: Heartbeat messages exchanged every 5 seconds detect trader failures within 3 seconds, marking inactive traders and broadcasting failure statuses.
- **Fault Tolerance**: Pending requests from failed traders are merged into the active traderâ€™s queue, ensuring uninterrupted processing via the heartbeat-driven failover mechanism.
